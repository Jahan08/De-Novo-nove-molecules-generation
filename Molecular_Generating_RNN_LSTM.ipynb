{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "\n",
        "Please read!\n",
        "This model takes in one-hot encoded molecules. This is essentially taking a String representation of a molecule and breaking it down into individual characters (characterized input).\n",
        "It processes a sequence of vector X, and taking as input each item x[i] in the sequence.\n",
        "\n",
        "The outputed molecules must be determined if chemically valid or not. In the future, we can check the validity by comparing molecules to the original SMILES\n",
        "input used for training. Once we find the common physiochemical features of the data, we can calculate the common physiochemical features for the data. In\n",
        "addition, executing a Principal Component Analysis (PCA) on the features, and transform the newly generated molecules accordingly.\n",
        "\n",
        "Model uses Tensorflow backed with Keras\n",
        "\n",
        "Comment out specific parts of the code depending on the use, between training, saving checkpoints, sampling, etc.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YroIyqP9qyv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lB-SlrRuqqtX"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from numpy.testing import assert_allclose\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening files, extracting data, and automatically closing them (SMILES strings are conjoined together with the \"\\n\" metatag)\n",
        "filename = '100k_rndm_zinc_drugs_clean.txt'\n",
        "with open(filename) as f:\n",
        "\t# f = [next(filename) for x in range(10000)]\n",
        "    \traw_text = \"\\n\".join(line.strip() for line in f)"
      ],
      "metadata": {
        "id": "1iBFvkidrDP4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating mapping for each char to integer, also mapping for the \\n (new line) is manually inserted into the dictionaries.\n",
        "unique_chars = sorted(list(set(raw_text)))\n",
        "# maps each unique character as int\n",
        "char_to_int = dict((c, i) for i, c in enumerate(unique_chars))\n",
        "# manually updates \\n\n",
        "char_to_int.update({-1 : \"\\n\"})\n",
        "\n",
        "# int to char dictionary\n",
        "int_to_char = dict((i, c) for i, c in enumerate(unique_chars))\n",
        "int_to_char.update({\"\\n\" : -1})"
      ],
      "metadata": {
        "id": "4pU2MDlerUfY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many unique characters\n",
        "mapping_size = len(char_to_int)\n",
        "reverse_mapping_size = len(int_to_char)\n",
        "print (\"Size of the character to integer dictionary is: \", mapping_size)\n",
        "print (\"Size of the integer to character dictionary is: \", reverse_mapping_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSBOLeS6rZr4",
        "outputId": "ccc04044-cc90-4144-a408-93868f9f7962"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the character to integer dictionary is:  35\n",
            "Size of the integer to character dictionary is:  35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert mapping_size == reverse_mapping_size"
      ],
      "metadata": {
        "id": "f_1eilNVrgUv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the loaded data to provide lengths for preparing datasets\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(unique_chars)\n",
        "\n",
        "print (\"Total number of characters in the file is: \", n_chars)\n",
        "\n",
        "# Preparring datasets by matching the dataset lengths (dataX will be the SMILES strings and dataY will be individual characters in the SMILE string)\n",
        "seq_length = 137\n",
        "dataX = []\n",
        "dataY = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQhXBFobrnAB",
        "outputId": "39c22cc3-ddea-4265-fa3e-012082b8ec10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters in the file is:  4530479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])"
      ],
      "metadata": {
        "id": "N0pS8Ehxrr82"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = len(dataX)"
      ],
      "metadata": {
        "id": "xPVctOJ7skKu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re shape input sequence X (using numpy)to be [samples, time steps, physiochemical features], input format for recurrent models\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# Normalize the integers in X by dividing by the number of unique SMILES characters (a.k.a vocabulary)\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# One-hot encode the output variable (so that they can be used to generate new SMILES after training)\n",
        "Y = np_utils.to_categorical(dataY)"
      ],
      "metadata": {
        "id": "zs4P0MtBsoOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"CREATING THE LSTM MODEL\"\"\"\n",
        "\n",
        "# Create the model (simple 2 layer LSTM)\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences = True))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(256, return_sequences = True))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(512, return_sequences = True))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(256, return_sequences = True))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(Y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "id": "qScxz48zudIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (model.summary())"
      ],
      "metadata": {
        "id": "_P9t966ZueK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "x_WoMa3iugpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define checkpoints (used to save the weights at each epoch, so that the model doesn't need to be retrained)\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# # Fit the model\n",
        "model.fit(X, Y, epochs = 5, batch_size = 512, callbacks = callbacks_list)"
      ],
      "metadata": {
        "id": "fmrnH1ROui6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"GENERATING NEW SMILES\"\"\"\n",
        "\n",
        "# Load the pre-trained network weights\n",
        "filename = \"weights-improvement-02-2.6436.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "metadata": {
        "id": "qZJuteZuullV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a random seed from the SMILES strings\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "id": "1vdsPd_Fusr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate specified number of characters in range\n",
        "for i in range(137):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "metadata": {
        "id": "r_lm43IWuvDF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}